{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UCLAIS Tutorial Series Challenge 2\n",
    "\n",
    "<!-- We are proud to present you with the second challenge of the 2022-23 UCLAIS tutorial series: the CIFAR-10 image classification problem. You will be introduced to a variety of core concepts in **computer vision** and specifically the implementation of convolutional neural network (CNN) architectures using the popular machine learning package, [TensorFlow](https://www.tensorflow.org/).\n",
    "\n",
    "This Jupyter notebook will guide you through the various general stages involved in end-to-end machine learning projects, including data visualisation, data preprocessing, model selection, model training and model evaluation. Finally, you will have the opportunity to submit the model you build to [DOXA](https://doxaai.com/) for evaluation on an unseen test set.\n",
    "\n",
    "This notebook contains blank code blocks for you to experiment with your own ideas in! See the `starter-SOLUTION.ipynb` notebook if you need more guidance.\n",
    "\n",
    "If you do not already have a DOXA account, you will want to [sign up](https://doxaai.com/sign-up) first before proceeding. -->\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing and Importing Useful Packages\n",
    "\n",
    "To get started, we will install a number of common machine learning packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds for reproducibility\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this gives live loss plots -- recommended\n",
    "from livelossplot import PlotLosses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now also make sure we're using out computer GPU for best performance. Make sure it says \"Using cuda device\" below. If not, go to \"Runtime\" -> \"Change runtime type\" in google colab and change to GPU. This will make model training a lot faster!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now load the data as a panda's dataframe. We use the [wine quality dataset](https://archive.ics.uci.edu/dataset/186/wine+quality). The goal of this challenge will be to use a neural network to predict the alcohol content of a wine given its other properties. The properties are based on physicochemical tests, and there are 10 features in total. The target variable is the alcohol content, which is a continuous variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "# !pip install ucimlrepo\n",
    "from ucimlrepo import fetch_ucirepo \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch dataset \n",
    "wine_quality = fetch_ucirepo(id=186) \n",
    "  \n",
    "# data (as pandas dataframes) \n",
    "df = wine_quality.data.features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Understanding\n",
    "Before we start to train our Machine Learning model, it is important to have a look and understand first the dataset that we will be using. This will provide some insights onto which model, model hyperparameter, and loss function are suitable for the problem we are dealing with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print the first five rows of the data\n",
    "\n",
    "# Hint: use the '.head()' method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print the number of rows and columns in the dataset \n",
    "\n",
    "# Hint: use '.shape'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Print the summary statistics for the dataset\n",
    "\n",
    "# Hint: use '.describe()'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we preprocess the data to make the data suitable for training. We will first split the data into training and validation sets. Feel free to add new cells as you see fit. (hint: it might be worth looking at normalizing the data to make training easier)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the data into X and y variables. X are the features and y is the target variable. we wand to predict. \n",
    "# We are trying to predict the alcohol content given the other variables. \n",
    "\n",
    "X = df.drop('alcohol', axis=1)\n",
    "y = df['alcohol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We done covert the Matrix X and vector y in numpy arrays.\n",
    "X = X.to_numpy()\n",
    "y = y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: split our features and output labels into separate training and test sets\n",
    "\n",
    "# HINT: Use train_test_split function from scikit-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define our Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now define the architecture of our model. Remember the more complex your model architecture, the more complex your data will be able to fit. However, this also means that your model will be more prone to overfitting. So be careful! You can also look at other ways of reducing overfitting such as regularization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_input_features, num_hidden_neurons = X_train.shape[1], 10\n",
    "model = nn.Sequential(\n",
    "    # TODO: add layers to our model\n",
    "\n",
    "    # Note: remember that we are trying to predict a continuous variable.\n",
    "    # Our output layer should have only one neuron, and our input layer should be the number of columns in X.\n",
    "\n",
    ")\n",
    "\n",
    "# Move model to GPU if available\n",
    "model = model.cuda() if torch.cuda.is_available() else model\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training our Model\n",
    "\n",
    "Now it's finally time to train our model! Make sure to use the training set to avoid overfittng! First, we define the hyperparameter. Feel free to experiment with those!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: change 'None' with values you think are appropriate. Experiment with different values to see what works best!\n",
    "learning_rate = None\n",
    "batch_size = None\n",
    "num_epochs = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your loss function below. Options are given in the [documentation](https://pytorch.org/docs/stable/nn.functional.html#loss-functions). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: replace 'None' with your loss function.\n",
    "\n",
    "# Hint: we are trying to predict a continuous variable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets also define our optimizer. Look at the [documentation](https://pytorch.org/docs/stable/optim.html#algorithms) for a list of optimization algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: replace 'None' with your optimizer.\n",
    "optim = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we set up our model for training and plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Keep track of losses\n",
    "plotlosses = PlotLosses()\n",
    "\n",
    "# Convert our training data to tensors\n",
    "X_train_tensor = torch.from_numpy(X_train).float().to(device)\n",
    "y_train_tensor = torch.from_numpy(y_train).float().to(device)\n",
    "\n",
    "# Change model to training mode\n",
    "model.train();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code cell below to train your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(num_epochs):\n",
    "    # TODO:  replace \"pass\" with the code to train your model. (hint: use plotlosses to see the live loss plot)\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating The Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now evaluate our trained model on the test set! We will use MSE to measure our accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change model to evaluation model\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    # Print the loss on the training data\n",
    "    y_pred_train = model(torch.from_numpy(X_train).float().to(device)).numpy()\n",
    "    mse_loss_train = np.mean((y_pred_train - y_train)**2) # Mean Square Error loss\n",
    "    print(f\"Train MSE loss: {mse_loss_train:.2f}\")\n",
    "    \n",
    "    # Print the loss on the test data\n",
    "    y_pred_test = model(torch.from_numpy(X_test).float().to(device)).numpy()\n",
    "    mse_loss_test = np.mean((y_pred_test - y_test)**2) # Mean Square Error loss\n",
    "\n",
    "    print(f\"Test MSE loss: {mse_loss_test:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing our DOXA Submission\n",
    "\n",
    "Once we are content with the performance of our model, we can submit the model to DOXA for evaluation on an unseen test set! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.1 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
